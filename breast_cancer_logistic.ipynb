{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入模块\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建特征列表表头\n",
    "column_names = ['Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']\n",
    "#使用pandas.read_csv函数从网上读取数据集\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data',names=column_names)\n",
    "#将？替换为标准缺失值表示\n",
    "data = data.replace(to_replace='?',value = np.nan)\n",
    "#丢弃带有缺失值的数据(只要有一个维度有缺失便丢弃)\n",
    "data = data.dropna(how='any')\n",
    "#查看data的数据量和维度\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/anaconda2-4.4.0/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    344\n",
       "4    168\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用sklearn.cross_validation里的train_test_split模块分割数据集\n",
    "from sklearn.cross_validation import train_test_split\n",
    "#随机采样25%的数据用于测试，剩下的75%用于构建训练集\n",
    "X_train,X_test,y_train,y_test = train_test_split(data[column_names[1:10]],data[column_names[10]],test_size = 0.25,random_state = 33)\n",
    "#查看训练样本的数量和类别分布\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    100\n",
       "4     71\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看测试样本的数量和类别分布\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从sklearn.preprocessing导入StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#从sklearn.linear_model导入LogisticRegression（逻辑斯蒂回归）\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#从sklearn.linear_model导入SGDClassifier（随机梯度参数）\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "#标准化数据，保证每个维度的特征数据方差为1，均值为，使得预测结果不会被某些过大的特征值而主导（在机器学习训练之前, 先对数据预先处理一下, 取值跨度大的特征数据, <br>我们浓缩一下, 跨度小的括展一下, 使得他们的跨度尽量统一.）\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)#初始化两种模型\n",
    "lr = LogisticRegression()\n",
    "sgdc = SGDClassifier()#调用逻辑斯蒂回归，使用fit函数训练模型参数\n",
    "lr.fit(X_train,y_train)#使用训练好的模型lr对x_test进行预测，结果储存在变量lr_y_predict中\n",
    "lr_y_predict = lr.predict(X_test)#调用随机梯度的fit函数训练模型\n",
    "sgdc.fit(X_train,y_train)#使用训练好的模型sgdc对X_test进行预测，结果储存在变量sgdc_y_predict中\n",
    "sgdc_y_predict = sgdc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 4,\n",
       "       2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 2,\n",
       "       4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2,\n",
       "       2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4,\n",
       "       2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2,\n",
       "       2, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 4, 4, 2, 2, 2,\n",
       "       2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 4, 4, 2, 4, 2, 2, 2, 2, 4,\n",
       "       4, 4, 2, 4, 2, 2, 4, 2, 4, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 4, 4, 4, 4, 4, 2, 2, 4, 4,\n",
       "       2, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4, 2, 2,\n",
       "       4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2,\n",
       "       2, 4, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4,\n",
       "       2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2,\n",
       "       2, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 4, 4, 2, 2, 2,\n",
       "       2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 4, 4, 2, 4, 2, 2, 2, 2, 4,\n",
       "       4, 4, 2, 4, 2, 2, 4, 2, 4, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc_y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy of LR Classifier:', 0.98830409356725146)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.99      0.99      0.99       100\n",
      "  Malignant       0.99      0.99      0.99        71\n",
      "\n",
      "avg / total       0.99      0.99      0.99       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#从sklearn.metrics导入classification_report\n",
    "from sklearn.metrics import classification_report\n",
    " \n",
    "#使用逻辑斯蒂回归模型自带的评分函数score获得模型在测试集上的准确性结果\n",
    "print('Accuracy of LR Classifier:',lr.score(X_test,y_test))\n",
    "#使用classification_report模块获得逻辑斯蒂模型其他三个指标的结果（召回率，精确率，调和平均数）\n",
    "print(classification_report(y_test,lr_y_predict,target_names=['Benign','Malignant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuarcy of SGD Classifier:', 0.97660818713450293)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.99      0.97      0.98       100\n",
      "  Malignant       0.96      0.99      0.97        71\n",
      "\n",
      "avg / total       0.98      0.98      0.98       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#使用随机梯度下降模型自带的评分函数score获得模型在测试集上的准确性结果\n",
    "print('Accuarcy of SGD Classifier:',sgdc.score(X_test,y_test))\n",
    "##使用classification_report模块获得随机梯度下降模型其他三个指标的结果\n",
    "print(classification_report(y_test,sgdc_y_predict,target_names=['Benign','Malignant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
